{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score, roc_curve\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains two columns:\n",
    "- category: the category of the email\n",
    "- text: the text of the email\n",
    "\n",
    "The dataset is available at [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection).\n",
    "\n",
    "We will read the dataset into a pandas dataframe then specify the category column as the label and the text column as the feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/spam.csv', encoding='ISO 8859-15')[['category', 'text']]\n",
    "X, y = df['text'].values, df['category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either count the number of word occurences per email to vectorize the emails, or we can use the TFIDF algorithm to vectorize the emails. The 3000 best features are selected using the chi-squared test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3000\n",
    "count = CountVectorizer(analyzer='word')\n",
    "X = count.fit_transform(X).toarray()\n",
    "X = SelectKBest(chi2, k=K).fit_transform(X, y)\n",
    "X = pd.DataFrame(X, columns=count.get_feature_names_out()[0:K])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a dataset with 3000 features, and we can use it to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 3000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>ever</th>\n",
       "      <th>every</th>\n",
       "      <th>every1</th>\n",
       "      <th>everybody</th>\n",
       "      <th>everyboy</th>\n",
       "      <th>everyday</th>\n",
       "      <th>everyone</th>\n",
       "      <th>everyones</th>\n",
       "      <th>everyso</th>\n",
       "      <th>everythin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.024408</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.040201</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.042330</td>\n",
       "      <td>0.076788</td>\n",
       "      <td>0.018944</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.018944</td>\n",
       "      <td>0.037867</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035425</td>\n",
       "      <td>0.188847</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.018944</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.046377</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.079114</td>\n",
       "      <td>0.317331</td>\n",
       "      <td>0.013397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                00          000       000pes  008704050406         0089  \\\n",
       "count  5572.000000  5572.000000  5572.000000   5572.000000  5572.000000   \n",
       "mean      0.001795     0.005205     0.000359      0.000179     0.000179   \n",
       "std       0.042330     0.076788     0.018944      0.013397     0.013397   \n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "max       1.000000     2.000000     1.000000      1.000000     1.000000   \n",
       "\n",
       "              0121  01223585236  01223585334   0125698789           02  ...  \\\n",
       "count  5572.000000  5572.000000  5572.000000  5572.000000  5572.000000  ...   \n",
       "mean      0.000179     0.000359     0.001436     0.000538     0.000179  ...   \n",
       "std       0.013397     0.018944     0.037867     0.023199     0.013397  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "              ever        every       every1    everybody     everyboy  \\\n",
       "count  5572.000000  5572.000000  5572.000000  5572.000000  5572.000000   \n",
       "mean      0.001256     0.024408     0.000179     0.000359     0.000179   \n",
       "std       0.035425     0.188847     0.013397     0.018944     0.013397   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     4.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          everyday     everyone    everyones      everyso    everythin  \n",
       "count  5572.000000  5572.000000  5572.000000  5572.000000  5572.000000  \n",
       "mean      0.001795     0.000179     0.004846     0.040201     0.000179  \n",
       "std       0.046377     0.013397     0.079114     0.317331     0.013397  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       2.000000     1.000000     2.000000     8.000000     1.000000  \n",
       "\n",
       "[8 rows x 3000 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).describe()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Naive Bayes classifier to train the model. We will use k-fold cross validation to test the model with k=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB(force_alpha=True, alpha=1)\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_test(y_pred: np.ndarray, y_test):\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = matrix.ravel()\n",
    "    return {\n",
    "        'confusion_matrix': {'tn': int(tn), 'fp': int(fp), 'fn': int(fn), 'tp': int(tp)},\n",
    "        'accuracy': round(accuracy_score(y_test, y_pred), 3),\n",
    "        'f1': round(f1_score(y_test, y_pred, pos_label='ham'), 3),\n",
    "        'recall': round(recall_score(y_test, y_pred, average=\"binary\", pos_label='ham'), 3),\n",
    "        'precision': round(precision_score(y_test, y_pred, pos_label='ham'), 3),\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each fold of the cross validation, we will train the model on the training set and test the model on the test set. We will calculate the accuracy and the root mean squared of the results of each fold. Finally, we will calculate the average of the root mean squared of the results of each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tn': 484, 'fp': 6, 'fn': 4, 'tp': 64}\n",
      "{'tn': 485, 'fp': 2, 'fn': 0, 'tp': 71}\n",
      "{'tn': 474, 'fp': 4, 'fn': 5, 'tp': 74}\n",
      "{'tn': 476, 'fp': 3, 'fn': 3, 'tp': 75}\n",
      "{'tn': 477, 'fp': 2, 'fn': 2, 'tp': 76}\n",
      "{'tn': 468, 'fp': 2, 'fn': 5, 'tp': 82}\n",
      "{'tn': 478, 'fp': 1, 'fn': 1, 'tp': 77}\n",
      "{'tn': 486, 'fp': 4, 'fn': 3, 'tp': 64}\n",
      "{'tn': 485, 'fp': 2, 'fn': 1, 'tp': 69}\n",
      "{'tn': 484, 'fp': 2, 'fn': 1, 'tp': 70}\n",
      "Accuracy: 0.990 +/- 0.005\n",
      "F1 Score: 0.995 +/- 0.003\n",
      "Recall: 0.994 +/- 0.003\n",
      "Precision: 0.995 +/- 0.004\n"
     ]
    }
   ],
   "source": [
    "scores = {'accuracy': [], 'f1': [], 'recall': [], 'precision': []}\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[\n",
    "        test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results = score_test(y_pred, y_test)\n",
    "    scores['accuracy'] += [results['accuracy']]\n",
    "    scores['f1'] += [results['f1']]\n",
    "    scores['recall'] += [results['recall']]\n",
    "    scores['precision'] += [results['precision']]\n",
    "    print(results['confusion_matrix'])\n",
    "print('Accuracy:', '%.3f +/- %.3f' %\n",
    "      (np.mean(scores['accuracy']), np.std(scores['accuracy'])))\n",
    "print('F1 Score:', '%.3f +/- %.3f' %\n",
    "      (np.mean(scores['f1']), np.std(scores['f1'])))\n",
    "print('Recall:', '%.3f +/- %.3f' %\n",
    "      (np.mean(scores['recall']), np.std(scores['recall'])))\n",
    "print('Precision:', '%.3f +/- %.3f' %\n",
    "      (np.mean(scores['precision']), np.std(scores['precision'])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
